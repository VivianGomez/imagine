I"V<p>b&gt;Platform:&lt;/b&gt; Mobile | Desktop. <br />
<b>Devices:</b> GearVR | Oculus Rift | HTC Vive <br />
<b>Game Engine:</b> Unity.<br />
<b>Context:</b> Virtual Reality.<br /></p>

<p>We propose a novel method to approximate the spatial perception between heterogeneous VR displays. Studies have shown that perception of distance in virtual reality (VR) is generally underestimated, not only in comparison with the physical world but also between different kinds of VR displays. This effect can be attributed to the interception of the action-perception-feedback loop in VR which causes a conﬂict between the visual and motor cues. Thus, the method is focused on approximating the spatial performance from a display with a greater interception degree to another display with a smaller interception degree. First, we iteratively adapt and assess the perception of distance in the display with the smaller interception degree by providing continuous feedback. Then, we approximate the spatial performance in the other display, by inﬂuencing its adaptation process and modifying how the visual cues are presented based on some display features.</p>

<center>
<b> Demo of size constancy test </b><br />
<iframe width="560" height="315" src="https://www.youtube.com/embed/2Ak0Pih7oXU" frameborder="0" allow="autoplay; encrypted-media" allowfullscreen=""></iframe>

<br /><br /><b> Demo of path integration task </b><br /><br />
<iframe width="560" height="315" src="https://www.youtube.com/embed/qxspaJOLxho" frameborder="0" allow="autoplay; encrypted-media" allowfullscreen=""></iframe>
</center>
<p><br /><br /></p>

:ET